{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realakash140/Customlinuxcomand/blob/main/Akash_RL_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ba0cb1-43a1-41db-b7cb-4a637a9550b4",
      "metadata": {
        "id": "c0ba0cb1-43a1-41db-b7cb-4a637a9550b4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the Environment Class\n",
        "class DeliveryEnvironment:\n",
        "    def __init__(self, num_riders, num_orders):\n",
        "        self.num_riders = num_riders\n",
        "        self.num_orders = num_orders\n",
        "        self.order_locations = np.random.uniform(0, 100, size=(num_orders, 2))\n",
        "        self.rider_locations = np.random.uniform(0, 100, size=(num_riders, 2))\n",
        "        self.rider_capacity = 5\n",
        "        self.state = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = {\n",
        "            \"rider_locations\": self.rider_locations.copy(),\n",
        "            \"order_status\": np.zeros(self.num_orders),  # 0 = unassigned, 1 = assigned\n",
        "            \"rider_orders\": [[] for _ in range(self.num_riders)],\n",
        "        }\n",
        "        return self.state\n",
        "\n",
        "    def step(self, rider_id, order_id):\n",
        "        if self.state[\"order_status\"][order_id] == 0 and len(self.state[\"rider_orders\"][rider_id]) < self.rider_capacity:\n",
        "            self.state[\"rider_orders\"][rider_id].append(order_id)\n",
        "            self.state[\"order_status\"][order_id] = 1  # Mark order as assigned\n",
        "            all_assigned = np.all(self.state[\"order_status\"] == 1)\n",
        "            return self.state, 10, all_assigned  # Reward for successful assignment\n",
        "        else:\n",
        "            return self.state, -1, False  # Penalty for invalid action\n"
      ],
      "metadata": {
        "id": "HxwN_w3ijZoy"
      },
      "id": "HxwN_w3ijZoy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Q-Learning Implementation\n",
        "class QLearningAgent:\n",
        "    def __init__(self, num_riders, num_orders, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
        "        self.num_riders = num_riders\n",
        "        self.num_orders = num_orders\n",
        "        self.q_table = np.zeros((num_riders, num_orders))\n",
        "        self.alpha = learning_rate\n",
        "        self.gamma = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        valid_actions = np.argwhere(state[\"order_status\"] == 0)\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            rider = random.randint(0, self.num_riders - 1)\n",
        "            order = random.choice(valid_actions[:, 0])\n",
        "            return rider, order\n",
        "        else:\n",
        "            max_q = -np.inf\n",
        "            best_action = (0, 0)\n",
        "            for rider in range(self.num_riders):\n",
        "                for order in valid_actions[:, 0]:\n",
        "                    if self.q_table[rider, order] > max_q:\n",
        "                        max_q = self.q_table[rider, order]\n",
        "                        best_action = (rider, order)\n",
        "            return best_action\n",
        "\n",
        "    def update_q_value(self, rider, order, reward, next_state):\n",
        "        next_valid_orders = np.argwhere(next_state[\"order_status\"] == 0)\n",
        "        max_next_q = 0 if len(next_valid_orders) == 0 else np.max(self.q_table[:, next_valid_orders[:, 0]])\n",
        "        self.q_table[rider, order] += self.alpha * (\n",
        "            reward + self.gamma * max_next_q - self.q_table[rider, order]\n",
        "        )\n"
      ],
      "metadata": {
        "id": "G4jNePQwjfZb"
      },
      "id": "G4jNePQwjfZb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Training the RL Agent\n",
        "def train_agent(env, agent, num_episodes):\n",
        "    performance_metrics = []\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            rider, order = agent.choose_action(state)\n",
        "            next_state, reward, done = env.step(rider, order)\n",
        "            agent.update_q_value(rider, order, reward, next_state)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "        performance_metrics.append(total_reward)\n",
        "        if episode % 10 == 0:\n",
        "            print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
        "\n",
        "    return performance_metrics"
      ],
      "metadata": {
        "id": "bD3ukznDjhPz"
      },
      "id": "bD3ukznDjhPz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    num_riders = 10\n",
        "    num_orders = 50\n",
        "    num_episodes = 100\n",
        "\n",
        "    env = DeliveryEnvironment(num_riders, num_orders)\n",
        "    agent = QLearningAgent(num_riders, num_orders)\n",
        "\n",
        "    performance_metrics = train_agent(env, agent, num_episodes)\n",
        "\n",
        "    print(\"Training Completed\")\n",
        "    print(\"Performance Metrics:\", performance_metrics)\n"
      ],
      "metadata": {
        "id": "z3Mur0n4jj3N",
        "outputId": "9ac6f355-2267-4936-a6d2-6f81c4e2779f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z3Mur0n4jj3N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: Total Reward = 326\n",
            "Episode 11: Total Reward = 389\n",
            "Episode 21: Total Reward = 442\n",
            "Episode 31: Total Reward = 425\n",
            "Episode 41: Total Reward = 472\n",
            "Episode 51: Total Reward = 394\n",
            "Episode 61: Total Reward = 361\n",
            "Episode 71: Total Reward = 467\n",
            "Episode 81: Total Reward = 361\n",
            "Episode 91: Total Reward = 373\n",
            "Training Completed\n",
            "Performance Metrics: [326, 462, 494, 449, 437, 464, 439, 374, 464, 476, 389, 366, 398, 460, 433, 459, 280, 416, 408, 440, 442, 342, 444, 352, 401, 289, 310, 450, 204, 426, 425, 352, 325, 441, 438, 331, 423, 436, 265, 403, 472, 373, 402, 427, 338, 474, 448, 212, 329, 421, 394, 351, 437, 429, 455, 405, 357, 428, 411, 430, 361, 422, 459, 472, 398, 361, 305, 282, 404, 387, 467, 454, 429, 465, 430, 466, 244, 378, 460, 354, 361, 393, 461, 404, 390, 336, 335, 448, 412, 380, 373, 400, 367, 339, 425, 423, 423, 473, 453, 413]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qB7VPecEjmOx"
      },
      "id": "qB7VPecEjmOx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "",
      "name": ""
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}